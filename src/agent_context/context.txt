Search Query: Anthropic Streamable HTTP API official blog documentation changelog
Search Answer: 根据所提供的资料，Anthropic 最新发布的 Streamable HTTP 的具体工程实现方案可以总结如下：

1.  **协议定位**: Streamable HTTP 是 **模型上下文协议（Model Context Protocol, MCP）** 框架内的一种服务器传输协议。它的核心设计目标是为运行 MCP 服务器提供**无状态（stateless）**支持。

2.  **Anthropic 的具体实现**: Anthropic 将这一方案实现为一个名为 **“MCP 连接器（MCP connector）”** 的功能，目前处于公开测试（public beta）阶段。这个连接器使得客户端（如 Anthropic 的 Messages API）能够直接连接到远程的 MCP 服务器。

3.  **连接方式**: 从客户端的角度来看，连接是通过在 Messages API 调用中使用一个名为 `mcp_servers` 的参数来实现的。该参数允许客户端与服务器建立直接的 HTTP 连接。

4.  **底层细节与未来发展**: 具体的底层工程细节是更广泛的 MCP 规范的一部分，现有资料引用了该规范但未深入展开。根据 MCP 的发展路线图，相关工作仍在进行中，旨在改进服务器启动和会话处理等方面，以便于在生产环境中更轻松地运行这些服务器。

Search Query: Anthropic "Model Context Protocol" (MCP) specification technical documentation
Search Answer: 根据提供的资料，Anthropic 近期发布的技术并非名为 "Streamable HTTP"，而是 **模型上下文协议 (Model Context Protocol, MCP)**。这是一个由 Anthropic 开发的开源协议，旨在为大型语言模型（LLM）应用与外部数据源、工具和工作流的集成提供一个标准化方案。

以下是关于模型上下文协议（MCP）的具体工程实现方案的综合概述：

#### **核心目标与理念**
MCP 的设计灵感来源于语言服务器协议（Language Server Protocol），其目标是创建一个统一的标准，就像 USB-C 为物理连接提供标准一样，从而简化 AI 应用与外部系统的连接方式。

#### **技术架构与传输层**
1.  **协议类型**: MCP 本质上是一个面向能力的远程过程调用（RPC）层。
2.  **传输机制**: 它使用 **JSON-RPC 2.0** 作为其核心传输协议。通过这种方式，AI 系统（客户端）和外部服务（服务器）可以进行标准化的通信。
3.  **客户端-服务器模型**:
    *   **MCP 服务器 (Server)**: 可以是网络设备、API 网关或任何希望向 AI 提供能力的服务。服务器将其管理的数据和操作作为“资源”、“提示”和“工具”暴露出来。
    *   **MCP 客户端 (Client)**: 通常是 AI 系统或 LLM 应用，它会发现并调用服务器提供的能力。

#### **核心概念与功能实现**

MCP 的主要功能通过以下几个核心概念实现：

*   **资源 (Resources)**: 服务器通过此功能向 AI 或用户提供上下文信息和数据。这是模型获取外部知识的主要方式。
*   **工具 (Tools)**: 服务器可以将其功能（例如现有的 API 路由）暴露为“工具”。AI 系统能够实时发现这些工具并调用它们来执行特定操作。例如，一个 MCP 服务器处理器可以自动将 API 网关的路由转换为可供 AI 调用的工具。
*   **提示 (Prompts)**: 服务器可以提供专门设计好的提示词或工作流，以引导 AI 更高效地完成特定任务。
*   **请求更多信息 (Elicitation)**: 这是一个由客户端提供的功能。当服务器需要用户提供额外信息才能完成任务时，它可以通过此机制向用户发起请求。

#### **安全考量**
由于 MCP 涉及到数据访问和代码执行，协议特别强调了安全性。在暴露任何用户数据或调用任何工具之前，主机（Host）必须获得用户的明确同意。

Search Query: Anthropic "Model Context Protocol" JSON-RPC 2.0 specification examples for defining tools and resources
Search Answer: 根据提供的资料，Anthropic 推出的相关协议是模型上下文协议（Model Context Protocol, MCP）。这是一个开放标准，旨在让 AI 应用能够通过一个基于 JSON-RPC 2.0 的客户端-服务器架构，连接到外部数据（资源）和工具（动作）。

在 MCP 的框架下，服务器可以向 AI 应用开放“资源”（Resources，即上下文和数据）和“工具”（Tools，即模型可以调用的动作）等功能。一个具体的工具概念示例是，AI 助手调用外部票务系统服务器上的 `create_ticket` 函数，来实时创建一张工程票据。

该协议基于 JSON-RPC 2.0，一个通用的 JSON-RPC 2.0 请求结构类似 `{"jsonrpc": "2.0", "method": "sum", "params": [1,2,4], "id": "1"}`。

然而，需要注意的是，所提供的资料中并未包含在 MCP 规范内具体如何定义和调用工具与资源的 JSON-RPC 2.0 代码示例。现有的 JSON 示例仅为通用的 JSON-RPC 调用（例如 `sum` 方法或错误处理），而非 MCP 特有的具体工程实现细节。

Search Query: Anthropic "Model Context Protocol" (MCP) github repository JSON-RPC method schema
Search Answer: 根据提供的资料，Anthropic 的相关工程实现方案是其**模型上下文协议（Model Context Protocol, MCP）**，该协议的具体实现细节如下。

MCP 协议建立在 JSON-RPC 2.0 的基础之上。JSON-RPC 2.0 是一个轻量级的远程过程调用（RPC）协议，用于标准化客户端与服务器之间的通信。该协议的模式（schema）定义了用于生命周期管理和核心功能（如工具、资源、提示词以及通过通知实现的实时更新）的数据层。

其核心 Schema 定义了以下关键的接口、方法和通知：

*   **JSONRPCRequest**: 代表一个期望获得响应的请求。这类请求包含一个唯一的识别ID，以便追踪响应。

*   **JSONRPCNotification**: 一种不需要响应的单向消息。这通常用于服务器向客户端发送实时更新。

*   **InitializeRequest**: 在初始连接建立期间使用的一种特定请求。它对于工具发现至关重要，允许客户端在连接时了解服务器所具备的能力。

*   **CancelledNotification**: 可由客户端或服务器任一方发送，用于取消先前发出的某个请求。

*   **RootsListChangedNotification**: 由客户端发送给服务器的通知，用于告知其“根列表”（list of roots）已发生变化。服务器在收到此通知后，应请求获取更新后的列表。

*   **响应结构 (Responses)**: Schema 同时为请求的成功响应和错误响应定义了相应的接口和数据结构。

*   **进度令牌 (progress token)**: 协议中还定义了一个进度令牌，用于将进度相关的通知与其原始请求关联起来，从而实现对长时间运行任务进度的追踪。

Search Query: Anthropic Model Context Protocol "InitializeRequest" parameters and schema definition
Search Answer: 根据提供的资料，虽然无法直接获得关于 Streamable HTTP 的具体实现方案，但资料详细介绍了 Anthropic 发布的另一个重要项目——模型上下文协议（Model Context Protocol, MCP）及其初始化请求（InitializeRequest）的工作机制。

`InitializeRequest` 是 MCP 中工具发现机制的核心组成部分。其主要目的和实现流程如下：

1.  **目的**：在初始化阶段，AI 应用程序的客户端（通过客户端管理器 client manager）与服务器建立连接，旨在发现并了解服务器所具备的能力（capabilities），例如可用的工具、资源和提示（prompts）。这使得客户端在实际尝试调用这些功能之前，就能预先掌握其可用性。

2.  **流程**：客户端管理器连接到已配置的服务器后，会发送 `InitializeRequest`。服务器响应后，客户端会存储这些发现的能力信息，以供后续使用。

3.  **技术基础**：客户端与服务器之间的通信是基于 JSON-RPC 2.0 协议的。该协议还支持通过通知（notifications）的方式进行实时更新。

尽管所提供的资料中未包含 `InitializeRequest` 的具体参数或 schema 定义，但 Anthropic 已经将包含这些技术细节的完整规范和 SDK 开源，并发布在 GitHub 上以供查阅。

Search Query: Anthropic "Model Context Protocol" "RootsListChangedNotification" JSON schema
Search Answer: `RootsListChangedNotification` 是模型上下文协议 (Model Context Protocol) 中的一个通知，由客户端发送给服务器。

**主要作用与流程：**

1.  **目的**：其核心目的是告知服务器，客户端可供服务器读取的资源列表（即 "roots" 列表）已经发生了变化。
2.  **触发机制**：当客户端的可用资源列表更新后，会向服务器发送这个可选的通知。
3.  **服务器响应**：服务器在接收到 `RootsListChangedNotification` 后，应主动发送一个 `ListRootsRequest` 请求，以获取并更新其所知的 roots 列表。

**技术定义：**

`RootsListChangedNotification` 在结构上被定义为一个 JSON-RPC 通知，它扩展了基础的 `Notification` 接口。其 TypeScript 接口定义如下：

```typescript
export interface RootsListChangedNotification extends Notification{}
```

相关的技术规范和 JSON schema 定义可以在 Model Context Protocol 的 GitHub 仓库中找到。

Search Query: Anthropic "Model Context Protocol" "progress token" JSON-RPC notification schema example
Search Answer: 根据提供的资料，相关的工程实现方案是一种名为“模型上下文协议”（Model Context Protocol, MCP）的开放标准。该协议基于 JSON-RPC 2.0，专为长时运行操作的进度追踪而设计。

其具体实现方案的核心机制如下：

1.  **基于 JSON-RPC 2.0 通知**：该协议利用标准的 JSON-RPC 2.0 通知（notification）消息来发送进度更新。根据规范，这类通知消息是单向的，发送后不期望收到响应。

2.  **使用 `progress_token` 进行关联**：为了将进度通知与发起操作的原始请求关联起来，协议中使用了一个名为 `progress_token` 的参数。当客户端发起一个长时操作请求时，可以附带这个令牌；随后，服务器在发送相关的进度更新通知时，会包含相同的 `progress_token`，从而让客户端能够识别这些更新属于哪个具体任务。

3.  **协议的模式定义**：该协议的模式（schema）通过 TypeScript 接口进行了定义。其中，关键的 `JSONRPCNotification` 接口结构如下：
    *   `method`: 一个字符串，用于指明要调用的方法。
    *   `params`: 可选参数，用于方法调用。
    *   `progress_token`: 一个可选的令牌，用于将此通知与特定请求关联起来。
    *   `metadata`: 一个可选字段，保留给客户端和服务器附加额外的元数据。

Search Query: Anthropic "Model Context Protocol" github full specification source code for JSON-RPC method schemas
Search Answer: 根据对所提供信息的综合分析，Anthropic 最新发布的 Streamable HTTP 的工程实现方案是基于一个名为 **“模型上下文协议”（Model Context Protocol, MCP）** 的规范，该规范利用 JSON-RPC 进行通信。

其在 GitHub 上的规范源代码定义了多种具体的请求、通知和响应类型，构成了其核心实现模式：

**1. 核心通信类型：**
*   **`JSONRPCRequest`**: 一种标准的请求类型，需要得到服务端的响应。每个请求都包含一个唯一的识别ID，以便将响应与请求对应起来。
*   **`JSONRPCNotification`**: 一种通知类型，发送后不需要响应。

**2. 具体的请求与通知：**
协议定义了多种具体的通信方法，例如：
*   **`InitializeRequest`**: 一种用于初始化的特定请求。
*   **`CancelledNotification`**: 允许通信的任何一方（客户端或服务器）发送此通知，用以取消一个先前已发出的请求。
*   **`RootsListChangedNotification`**: 由客户端发送给服务器的通知，用于告知“根列表”（list of roots）已发生更改。服务器在收到此通知后，应使用 `ListRootsRequest` 请求来获取更新后的列表。

**3. 进度跟踪与响应结构：**
*   **进度令牌 (progress token)**: 协议中定义了一个关键概念——“进度令牌”。该令牌用于将流式传输过程中的进度通知与原始的请求关联起来，从而实现对长时间运行任务的状态跟踪。
*   **响应结构**: 协议还为成功的响应和包含错误的响应分别定义了标准化的数据结构。

**来源参考:**
*   [https://github.com/modelcontextprotocol/specification/blob/main/schema/2025-03-26/schema.ts](https://github.com/modelcontextprotocol/specification/blob/main/schema/2025-03-26/schema.ts)

Search Query: Anthropic "Model Context Protocol" (MCP) github JSON-RPC examples for tool use and resource fetching
Search Answer: 根据提供的资料，虽然用户查询的是“Streamable HTTP”，但所有候选答案都指向了Anthropic推出的一个名为“模型上下文协议”（Model Context Protocol, MCP）的开放标准。以下是基于这些资料整合的关于MCP工程实现方案的研究。

Anthropic的模型上下文协议（Model Context Protocol, MCP）是一个开放标准，旨在让AI智能体（AI agents）能够以安全、一致的方式与外部工具和数据源进行交互。该协议的核心是一个基于JSON-RPC 2.0的数据层，负责处理所有客户端与服务器之间的通信，包括生命周期管理以及与工具（tools）、资源（resources）和提示（prompts）等基础元素的交互。

其具体的工程实现方案主要包括以下几个关键环节：

### 1. 工具发现 (Tool Discovery)
这是实现交互的第一步。客户端首先需要连接到服务器，并发现服务器所能提供的能力，例如有哪些可用的工具。这是MCP的一个基础机制，允许客户端在使用工具前先对其有所了解。
*   **实现示例**：客户端可以通过发送一个请求来获取可用工具的列表，示例代码如下：
    ```javascript
    const tools = await client.listTools();
    ```

### 2. 工具执行与调用 (Tool Execution and Invocation)
当大语言模型（LLM）根据用户需求决定使用某个工具时，客户端会执行该工具。
*   **实现流程**：
    1.  **记录意图**：客户端会记录LLM的调用意图和相关参数。例如，通过日志输出：
        ```
        LLM wants to call tool: ${name}
        Tool arguments: [args]
        ```
    2.  **发送请求**：客户端将用户的消息和可用的工具信息一起发送给语言模型，以触发工具调用。示例代码如下：
        ```javascript
        const response = await llmClient.sendMessage(messages, { tools });
        ```
    3.  **执行并记录结果**：客户端执行工具并记录返回结果，日志中可能包含如下信息：
        ```
        Executing tool ${toolName} on server ${toolInfo.serverId}
        Tool result: ${result.content[0].text}
        ```

### 3. 实时更新与通知 (Real-time Updates and Notifications)
MCP支持通过JSON-RPC 2.0的通知消息（notification messages）进行实时更新。
*   **实现机制**：服务器可以主动向客户端发送通知，告知其状态变化（例如工具或资源更新），而无需等待客户端的明确请求。这种推送机制使得客户端不必通过轮询（polling）来获取最新状态，保证了数据同步的效率。

### 应用实例
该协议已被用于创建多种开源的MCP服务器，使LLM能够受控地访问多样化的系统，包括：
*   **数据库**：如Snowflake、ArangoDB。
*   **云服务**：如阿里巴巴云服务。
*   **第三方API**：如百度地图（Baidu Maps）和电影数据库（The Movie Database, TMDB）。

Search Query: github modelcontextprotocol/specification schema.ts "InitializeRequest" "ClientCapabilities" typescript interface definition
Search Answer: 根据提供的资料，关于Anthropic Streamable HTTP的工程实现方案，相关信息指向了模型上下文协议（Model Context Protocol, MCP）规范中的一个`schema.ts`文件。

在该文件中，可以找到一个`InitializeRequest`接口的TypeScript定义，该接口继承自`Request`接口。具体的代码片段如下：

```typescript
export interface InitializeRequest extends Request{
```

然而，当前可用的资料是不完整的。资料中并未提供`InitializeRequest`接口的完整定义，也没有提供`ClientCapabilities`的具体TypeScript接口定义。

资料来源：[https://github.com/modelcontextprotocol/specification/blob/main/schema/2025-03-26/schema.ts](https://github.com/modelcontextprotocol/specification/blob/main/schema/2025-03-26/schema.ts)

Search Query: github modelcontextprotocol/specification/blob/main/schema/2025-03-26/schema.ts source code for "InitializeRequest", "ClientCapabilities", and "ServerCapabilities" typescript interfaces
Search Answer: 根据提供的资料，Anthropic 的 Streamable HTTP 工程实现基于一个名为“模型上下文协议”（Model Context Protocol, MCP）的规范。其具体的实现方案涉及客户端与服务器之间的初始化和能力协商过程。

核心组件与流程如下：

1.  **`InitializeRequest` (初始化请求)**:
    *   客户端向服务器发送一个 `InitializeRequest` 请求。
    *   此请求中包含一个关键字段 `protocolVersion`，用于表明客户端所支持的最新协议版本。

2.  **`ClientCapabilities` 与 `ServerCapabilities` (客户端与服务器能力)**:
    *   这些是用于特性协商的组件。服务器会检查客户端在 `ClientCapabilities` 中声明的能力。
    *   根据客户端支持的能力，服务器代码可以有条件地启用或禁用特定的功能。

3.  **响应与版本确认**:
    *   如果服务器支持客户端请求中声明的 `protocolVersion`，它会在响应中返回（echo）相同的版本号，完成协议版本的确认。

虽然无法从现有资料中获取 `InitializeRequest` 等接口的 TypeScript 源代码（`schema.ts` 文件内容缺失），但可以明确以下几点：

*   **正式规范**: 这些数据结构的完整和正式的规范被定义在一个 `schema.json` 文件中。
*   **官方 SDK**: Anthropic 提供了官方的 SDK 用于实现 MCP，包括 TypeScript 和 Rust 版本，这些 SDK 可以在 GitHub 上找到，其中包含了具体的工程实现代码。

Search Query: site:github.com modelcontextprotocol/specification/blob/main/schema/2025-03-26/schema.ts raw content for InitializeRequest RootsListChangedNotification
Search Answer: 根据提供的资料，我们无法找到关于 Anthropic Streamable HTTP 中 `InitializeRequest` 或 `RootsListChangedNotification` 的具体 schema 定义或原始代码内容。

综合现有信息可以得出以下结论：

1.  **缺乏具体实现细节**：提供的资料主要包含文件元数据、协议版本的链接以及相关的 GitHub 仓库信息，但并未包含这些接口的具体代码实现。

2.  **协议类型**：资料中提到，该协议是一种基于 JSON-RPC 的协议，并利用了像 `RequestId`、`JSONRPCRequest` 和 `JSONRPCNotification` 这样的标准元素。

3.  **定义位置**：尽管无法直接查看代码，但这些 schema 定义通常会位于 Model Context Protocol 的 GitHub 仓库中的 `schema.ts` 等规范文件内。

总而言之，现有信息尚不足以提供关于 Streamable HTTP 的具体工程实现方案。

Search Query: github modelcontextprotocol/specification schema.json content for InitializeRequest RootsListChangedNotification progress_token
Search Answer: 根据模型上下文协议（Model Context Protocol, MCP）的规范，其具体实现方案中的一些组件定义如下：

*   **InitializeRequest**：这是一个需要响应的请求，被定义为扩展了基础 `Request` 接口的接口。

*   **RootsListChangedNotification**：这是一种从客户端发送到服务器的通知，用于告知服务器根列表（list of roots）已发生更改。该通知本身是一个扩展了 `Notification` 的接口。服务器在收到此通知后，应通过 `ListRootsRequest` 来请求更新后的根列表。

*   **progress_token**：这是一个用于将进度通知与发起它们的原始请求关联起来的令牌（token）。这对于长时间运行的操作尤其有用。如果客户端在请求的元数据（metadata）中包含了一个 `progressToken`，服务器就可以向该客户端回送 `notifications/progress` 消息，以报告进度。

Search Query: raw content of file "schema.ts" from github repository "modelcontextprotocol/specification"
Search Answer: 根据提供的资料，目前没有关于 Anthropic 最新发布的 "Streamable HTTP" 工程的具体实现方案的信息。

所有候选答案均指出，现有资料讨论的是一个名为“模型上下文协议”（Model Context Protocol, MCP）的项目，而非 Streamable HTTP。尽管 Anthropic 参与了 MCP 项目（提交记录中出现了 "Claude <noreply@anthropic.com>"），但这与用户查询的 Streamable HTTP 是不同的概念。

关于模型上下文协议（MCP）的要点如下：

*   **目的**：MCP 是一种标准化协议，旨在让服务器（如 IDE 或其他工具）能够向语言模型等客户端提供文件、数据库模式等上下文资源。
*   **技术基础**：该协议建立在 JSON-RPC 之上，用于处理请求和通知。`schema.ts` 文件使用 TypeScript 定义了协议的数据结构，例如 `JSONRPCRequest` 和 `JSONRPCNotification` 等接口。
*   **核心功能**：客户端可以订阅特定的资源，并在这些资源发生变化时接收到来自服务器的通知。
*   **开发要求**：该规范的开发需要 Node.js 20 或更高版本以及 TypeScript。

综上所述，提供的材料详细介绍了模型上下文协议（MCP）及其与 Anthropic 的关联，但并未包含有关 "Streamable HTTP" 的具体工程实现细节。

Search Query: raw content of file "schema.json" from github repository "modelcontextprotocol/specification" path "schema/2025-03-26/schema.json"
Search Answer: 根据提供的资料，Anthropic 最新发布的 Streamable HTTP 的工程实现方案可以从其所属的协议、数据结构、传输机制和特定功能等多个层面进行解析。这是一个结合了开放协议、标准HTTP特性和特定功能设计的综合方案。

### 1. 核心协议：模型上下文协议 (Model Context Protocol, MCP)

Streamable HTTP (S-HTTP) 并非一个独立的技术，而是“模型上下文协议”（Model Context Protocol, MCP）的第一个具体实现方案。MCP是一个开放标准，旨在解决现有流式传输技术（如Server-Sent Events和分块传输编码）仅能传输非结构化“字节包”的局限性，提供一种结构化、双向、支持多路复用和流控制的通信方式。有讨论认为，该协议可能构建于HTTP/2或HTTP/3之上，以利用其底层能力实现这些高级特性。

### 2. 协议层：JSON Schema 定义的数据结构

该协议的具体数据结构通过一个开放的JSON Schema来定义，确保了通信内容的结构化和标准化。根据其`2025-03-26`版本的schema，核心数据结构包括：

*   **协议与版本标识**：每个消息体都包含 `protocol`（固定为 "model-context-protocol"）和 `version`（如 "2025-03-26"）字段，用于版本控制。
*   **顶层字段**：消息体包含 `metadata`（元数据）、`tool_definitions`（工具定义）、`content`（内容）、`usage`（用量统计）、`stop_reason`（停止原因）等关键字段。
*   **内容块 (Content Blocks)**：`content` 字段是一个数组，可以容纳多种类型的内容块，如 `text` (文本)、`image` (图像)、`tool_use` (工具使用请求) 和 `tool_result` (工具执行结果)。每种内容块都有其特定的数据结构。

### 3. 传输层：基于 `multipart/mixed` 的 REST 流式传输

在具体的HTTP工程实现上，Streamable HTTP利用了标准的 `multipart/mixed` 响应类型来兼容现有的HTTP基础设施，其具体方案如下：

1.  **HTTP响应头**：服务器返回的HTTP响应头中，`Content-Type` 被设置为 `multipart/mixed`，并定义一个边界字符串（boundary）来分隔响应体的不同部分。

2.  **Multipart结构化响应体**：
    *   **第一部分（头部/元数据）**：这是流的元数据部分，其 `Content-Type` 为 `application/json`。它对应MCP规范中的 `StreamStartEvent` 事件，包含了流的类型（`stream_type`）和整个消息的元数据（如 `message_id`, `model`, `role` 等）。
    *   **中间部分（数据块）**：在元数据之后，是任意数量的数据块。这些部分的 `Content-Type` 建议为 `application/json;type=chunk`。它们对应规范中的 `StreamMessageEvent` 事件，通常包含类型为 `content_delta` 的数据，用于流式传输文本增量（`TextBlock` delta）。
    *   **结束部分（尾部）**：流的最后是一个对应 `StreamEndEvent` 事件的部分，它标志着流的结束，并提供最终的停止原因（`stop_reason`）和用量统计（`usage`）。

### 4. 特定功能：大型上下文的流式输入 (Streamable Inputs)

除了对模型输出进行流式传输，该方案还通过一个巧妙的设计实现了对大型输入的“流式处理”。

*   **`streamable` 标志位**：在MCP的 `ContentBlock` 对象中，增加了一个 `streamable` 布尔标志位。
*   **按需引用加载**：当客户端需要在请求中包含一个非常大的内容块（如整个代码库或大型文档）时，可以将该内容块的 `streamable` 标志设置为 `true`。此时，请求载荷中不包含内容的实际数据，而是在 `url` 字段中提供一个可访问该内容的URL。
*   **模型按需拉取**：模型在处理请求时，会根据需要从这个URL流式传输数据，而不是要求客户端在每次API调用时都上传完整的、庞大的内容。这极大地减少了请求的体积和延迟，实现了对输入的“流式”引用。

综上所述，Anthropic的Streamable HTTP工程方案是一个分层设计：以开放的**模型上下文协议（MCP）**及其**JSON Schema**为基础定义了结构化数据；利用标准的**HTTP `multipart/mixed`** 机制实现了兼容性强的流式响应传输；并通过**`streamable`标志与URL引用**的创新设计，解决了大上下文输入的效率问题。整个方案的规范已在GitHub上开源。

Search Query: raw content of file "schema.ts" from github repository "modelcontextprotocol/specification" path "schema/2025-03-26/schema.ts"
Search Answer: 根据提供的资料，其中并未包含关于Anthropic最新发布的Streamable HTTP的具体工程实现方案的信息。

这些资料主要讨论的是一个名为“模型上下文协议”（Model Context Protocol, MCP）的主题，包括其 schema 系统和开发工作流程，这与您查询的 Anthropic Streamable HTTP 并不相关。

Search Query: view raw file content for "schema.ts" from github.com/modelcontextprotocol/specification/blob/main/schema/2025-03-26/schema.ts
Search Answer: 根据提供的资料，其中并未包含有关 Anthropic 最新发布的 Streamable HTTP 的具体工程实现方案。

不过，资料中提到了一个名为“模型上下文协议”（Model Context Protocol, MCP）的规范，该协议可能与此相关。以下是关于 MCP 的信息摘要：

*   **核心规范**：所有在 MCP 客户端和服务器之间传递的消息都必须遵循 JSON-RPC 2.0 规范，这包括请求、响应和通知。
*   **Schema 作为事实来源**：MCP 使用一个 TypeScript schema 文件（`schema.ts`）作为所有协议消息、类型和结构的唯一事实来源 (single source of truth)。
*   **消息结构**：
    *   响应（Responses）必须包含与其对应的请求（Request）相同的 ID。
    *   响应必须包含一个 `result` 对象或一个带有代码和消息的 `error` 对象。
*   **协议定义的消息类型**：该协议定义了多种客户端-服务器间的消息，例如：
    *   列出和读取资源 (`resources/list`, `resources/read`)
    *   列出工具 (`tools/list`)
    *   资源更新时的通知

综上所述，虽然无法找到关于 Streamable HTTP 的直接实现细节，但相关资料描述了一个基于 JSON-RPC 2.0 和 TypeScript schema 的模型上下文协议 (MCP)。

Search Query: "Model Context Protocol" (MCP) official client SDK source code for python OR typescript multipart/mixed parsing github
Search Answer: 关于 Anthropic 最新发布的 Streamable HTTP，其官方实现被称为“模型上下文协议”（Model Context Protocol, MCP）。相关的官方 SDK 源代码可以在其 GitHub 组织 `modelcontextprotocol` (https://github.com/modelcontextprotocol) 中找到。

具体来说，相关的代码仓库包括：

*   **Python SDK**: `https://github.com/modelcontextprotocol/python-sdk`
*   **TypeScript SDK**: `https://github.com/modelcontextprotocol/typescript-sdk`

其中，TypeScript SDK 包含了用于构建服务器的 `@modelcontextprotocol/server` 包和用于构建客户端的 `@modelcontextprotocol/client` 包。

虽然这些代码仓库是查找具体工程实现方案的正确位置，但当前所提供的信息中并未包含这些 SDK 内部关于 `multipart/mixed` 内容解析的具体源代码文件或实现细节。如需深入研究，可以直接浏览上述仓库中的代码。

Search Query: github modelcontextprotocol/typescript-sdk source code client parse multipart/mixed response stream
Search Answer: 根据提供的资料，关于 Anthropic Streamable HTTP 的具体工程实现方案，要点如下：

*   **核心实现文件**：客户端处理 Streamable HTTP 响应流的具体工程实现位于 Model Context Protocol (MCP) TypeScript SDK 的 `@modelcontextprotocol/client` 包内，文件路径为 `packages/client/src/client/streamableHttp.ts` [2, 3]。
*   **技术细节**：该实现支持通过服务器发送事件 (Server-Sent Events, SSE) 进行流式传输，并涉及到解析 `multipart/mixed` 类型的响应 [2]。
*   **官方推荐与兼容性**：这是官方推荐的用于远程服务器的传输方式。为了向后兼容，项目中也保留了一个旧版的 HTTP+SSE 传输实现，位于 `packages/client/src/client/sse.ts` [2]。
*   **示例代码**：开发者可以参考 `src/examples/client/simpleStreamableHttp.ts` 文件中的示例来了解如何使用这个 Streamable HTTP 客户端 [1, 5]。
*   **已知问题**：该 Streamable HTTP 传输层存在一个已知问题，即在处理并发连接时，由于会话数据隔离不当，可能会导致不同客户端之间的响应发生混淆 [4]。

Search Query: view raw file content for "streamableHttp.ts" from github.com/modelcontextprotocol/typescript-sdk/blob/main/packages/client/src/client/streamableHttp.ts
Search Answer: 根据提供的资料，Anthropic 最新发布的 Streamable HTTP 的具体工程实现方案是通过模型上下文协议（Model Context Protocol, MCP）的 TypeScript SDK 以示例代码的形式提供的，而非 Anthropic 直接发布的技术。这些可运行的示例文件为开发者提供了具体的服务器端和客户端实现方案。

### 服务器端实现方案 (Server-Side Implementations)

SDK 在 `src/examples/server` 目录下提供了多种服务器实现，以满足不同场景的需求：

*   **核心有状态实现 (Stateful Server)**: 文件 `simpleStreamableHttp.ts` 是一个功能丰富的核心范例，支持工具（tools）、资源（resources）、提示（prompts）、任务（tasks）、采样（sampling）和日志等功能，并包含可选的 OAuth 功能。
*   **无状态实现 (Stateless Server)**: 文件 `simpleStatelessStreamableHttp.ts` 展示了另一种无状态的服务器实现方式。
*   **JSON 响应模式 (JSON Response Mode)**: 文件 `jsonResponseStreamableHttp.ts` 是一个变体，其响应格式为 JSON。
*   **向后兼容实现 (Backwards-Compatible Server)**: 文件 `sseAndStreamableHttpCompatibleServer.ts` 用于同时支持新的 Streamable HTTP 客户端和传统的 SSE (Server-Sent Events) 客户端，确保平滑过渡。
*   **GET + SSE 通知实现**: 文件 `standaloneSseWithGetStreamableHttp.ts` 展示了如何结合使用 Streamable HTTP GET 请求和 SSE 来处理通知。

### 客户端实现方案 (Client-Side Implementations)

SDK 同样在 `src/examples/client` 目录下提供了客户端的实现示例：

*   **交互式客户端 (Interactive Client)**: 客户端目录下的 `simpleStreamableHttp.ts` 文件是一个交互式命令行界面（CLI）客户端，用于演示如何与 Streamable HTTP 服务器进行交互，包括调用工具、资源、提示和任务等功能。
*   **回退客户端 (Fallback Client)**: 文件 `streamableHttpWithSseFallbackClient.ts` 展示了如何实现一个能够从 Streamable HTTP 优雅地回退到 SSE 的客户端，以兼容不支持新协议的服务器。

此外，这些示例代码和相关文档中还体现了更详细的工程实践，例如 CORS（跨源资源共享）和 DNS 重绑定保护等安全措施。

Search Query: Model Context Protocol (MCP) server architecture guide for session context management and tool call execution
Search Answer: 根据提供的资料，以下是对模型上下文协议（Model Context Protocol, MCP）工程实现方案的研究，该协议旨在标准化语言模型与外部工具及数据的连接方式。

### 核心架构

模型上下文协议 (MCP) 采用基于 JSON-RPC 2.0 的客户端-主机-服务器 (client-host-server) 架构。在此模型中，一个主机应用程序负责管理多个客户端，每个客户端都与提供特定功能的服务器保持一个隔离的、一对一的连接。这种设计旨在促进安全、有状态且由模式驱动的通信。

### 服务器能力定义

MCP 服务器通过三个核心概念来暴露其能力，所有这些概念都使用 JSON Schema (Draft 2020-12) 进行描述，从而允许客户端在执行前进行输入和输出结构的验证：

*   **资源 (Resources)**：为 AI 提供结构化的信息访问，用于获取上下文。例如，用户的日历可用性、旅行历史或偏好设置。
*   **工具 (Tools)**：代表 AI 可以执行的功能或动作。例如，搜索航班、预订酒店等。
*   **提示 (Prompts)**：作为预构建的指令模板，引导模型如何组合使用特定的工具和资源来完成复杂的任务或工作流。

### 会话与上下文管理

MCP 是一个专注于上下文交换的有状态协议。会话开始于一个能力协商阶段，客户端和服务器会明确声明各自支持的功能，以确保双方在功能上的兼容性。在会话期间，AI 通常会首先从相关资源中读取信息以收集上下文，然后在提示的引导下使用工具来执行任务。

### 工具调用执行流程

该协议将工具的调用过程清晰地分为三个阶段：发现、模式验证和执行。

1.  **发现**：客户端连接到服务器后，可以请求一份可用的工具列表。
2.  **决策与验证**：语言模型根据用户查询决定需要使用哪些工具。由于工具通过 JSON Schema 定义，客户端可以在调用前验证输入参数的结构，确保了类型安全和模式优先的集成方法。
3.  **执行**：在验证通过后，客户端执行相应的工具调用。

### 部署方案

MCP 服务器可以灵活部署在不同环境中：

*   **本地部署**：与 AI 应用程序一同部署在本地。
*   **远程部署**：部署在云服务上，可供多个 AI 应用共享。远程服务器可以利用 Server-Sent Events (SSE) 等传输方式实现实时数据流。
*   **推荐平台**：对于复杂的企业级或有状态应用，常见的部署基础设施包括托管的无服务器平台（如 Cloud Run）或容器编排服务（如 Google Kubernetes Engine, GKE）。

Search Query: Model Context Protocol vs OpenAI Assistants API vs Google AI Function Calling protocol design comparison
Search Answer: 根据提供的资料，Anthropic、OpenAI 和 Google 在模型与外部工具交互的协议设计上各有侧重，具体实现方案如下：

### Anthropic：模型上下文协议 (Model Context Protocol, MCP)

Anthropic 的方案是一种开放、模型无关的协议，旨在为 AI 模型与外部工具及数据源的交互提供一个标准化的接口。其核心设计理念和实现方式如下：

*   **目标与定位**：MCP 被比作“AI 领域的 USB-C”，其目标是为工具访问建立一个持久化、双向的标准化连接。它是一个开放协议，由 Anthropic 主导，但其规范和 SDK 是开源的，任何模型或客户端都可以采用。
*   **技术架构**：该协议在技术上是传输无关的（transport-agnostic），可以在 HTTP 或 stdio 等不同传输层上运行。它采用 JSON-RPC 作为核心通信机制。
*   **工作流程**：
    1.  **连接与发现**：一个“主机”（Host，如 IDE、应用程序或 Agent 运行时）与“服务器”（Server）建立一个持久会话。
    2.  **工具发现**：主机通过发送一个 `tools/list` 命令来发现服务器上可用的工具。
    3.  **工具调用**：主机使用 `tools/call` 命令在会话中调用特定工具。
    这种基于会话的设计强调了持续连接和能力协商（capability negotiation）。

### 与其他方案的比较

**1. OpenAI：函数调用/Assistants API**

*   **设计理念**：与 MCP 的持久化连接模型相反，OpenAI 的方法被描述为一种轻量级、基于单次调用（per-call）的模式。
*   **实现方式**：它通常利用 OpenAPI (OAS) 3.1 规范文档来描述 HTTP 服务。然后，一个代理或工具层会将这些服务定义转换为模型可以调用的函数。

**2. Google：Agent-to-Agent (A2A) 协议**

*   **设计理念**：A2A 协议专门为大型、企业级的多智能体（multi-agent）协作生态系统而设计。
*   **实现方式**：它定义了一种用于消息、线程、函数调用和流式事件的共享格式。这使得来自不同供应商（如 Salesforce、SAP、Atlassian 等）的专用智能体能够相互发现并调用对方的能力，以完成复杂的工作流。A2A 是一个由 Google 和超过50个生态系统合作伙伴支持的开放协议。

综上所述，Anthropic 的 MCP 侧重于建立一个通用的、持久化的工具连接标准；OpenAI 的方案更为轻量级，采用按次调用的模式；而 Google 的 A2A 协议则专注于解决企业环境中多智能体之间的大规模协作问题。

Search Query: ("Model Context Protocol" OR "MCP") developer feedback OR review OR discussion site:news.ycombinator.com OR site:reddit.com OR site:github.com
Search Answer: 根据提供的资料，您查询的“Streamable HTTP”的具体实现方案指向一个名为“模型上下文协议”（Model Context Protocol, MCP）的开放标准。该协议旨在标准化AI应用（客户端或主机）与外部数据源和工具（服务器）的连接与交互方式。

### 模型上下文协议（MCP）概述

模型上下文协议（Model Context Protocol, MCP）是一个开放标准，其目标是为大型语言模型（LLM）和代理式AI（Agentic AI）提供一个结构化框架，使其能够与外部系统进行自主、安全且富含上下文的交互。这一定位类似于API或语言服务器协议（Language Server Protocol）在其他应用集成领域所扮演的角色 [https://github.com/asinghcsu/model-context-protocol-survey, https://github.com/cyanheads/model-context-protocol-resources/blob/main/guides/mcp-server-development-guide.md]。

### 核心架构

MCP的架构主要包含三个组件：

1.  **MCP主机 (MCP Host)**：指AI应用程序本身，例如GitHub Copilot [https://github.com/orgs/community/discussions/174921]。
2.  **MCP服务器 (MCP Servers)**：独立的本地或远程进程，负责提供上下文、工具、资源和提示（Prompts）[https://github.com/orgs/community/discussions/174921, https://github.com/cyanheads/model-context-protocol-resources/blob/main/guides/mcp-server-development-guide.md]。
3.  **协议层 (Protocol Layer)**：用于实现主机与服务器之间的通信 [https://github.com/orgs/community/discussions/174921]。

### 工程实现方案

在具体的工程实现中，MCP利用流式传输技术来处理需要多次通信的场景：

*   **流式通信机制**：当服务器需要针对客户端的单个请求发送多条消息时（例如，分块返回大型结果或在持久连接上持续通信），它会采用**服务器发送事件（Server-Sent Events, SSE）**流。这使得服务器可以主动向客户端推送数据 [https://github.com/cyanheads/model-context-protocol-resources/blob/main/guides/mcp-server-development-guide.md]。

*   **处理长时运行操作**：对于需要较长时间才能完成的任务，协议设计了进度通知机制。如果客户端在初始请求中提供了一个 `progressToken`，服务器就可以在操作过程中向客户端发送 `notifications/progress` 消息，以实时更新任务进展情况 [https://github.com/cyanheads/model-context-protocol-resources/blob/main/guides/mcp-server-development-guide.md]。

### 生态系统与应用

*   **多语言支持**：MCP项目提供了多种主流编程语言的官方SDK，包括TypeScript、Python、Java、C#、Go、Rust和Ruby，方便开发者集成 [https://github.com/modelcontextprotocol]。

*   **社区实践**：社区已经涌现出一些基于MCP的实现，例如用于自动化代码分析和反馈的服务器 `code-feedback`、Emacs集成插件 `Emacs Mcp` 以及用于TypeScript AI代理的 `SpinAI` 等 [https://github.com/niradler/code-feedback, https://github.com/asinghcsu/model-context-protocol-survey]。

*   **团队协作优势**：在团队环境中，MCP可以通过共享的上下文服务器来维持项目知识的一致性。这使得AI助手能够即时获取所有成员所需的上下文信息，而无需开发者中断当前工作流程 [https://github.com/orgs/community/discussions/174921]。

Search Query: source code from "packages/client/src/client/streamableHttp.ts" in github repository "modelcontextprotocol/typescript-sdk" showing multipart/mixed stream parsing
Search Answer: 根据提供的资料，Anthropic 的 Streamable HTTP 的具体工程实现方案因源代码（`streamableHttp.ts`）缺失而无法进行深度解析，特别是关于 `multipart/mixed` 流解析的具体细节。然而，通过整合现有文档信息，可以总结出其高层级的架构和实现要点：

*   **定位与角色**: Streamable HTTP 是在模型上下文协议（Model Context Protocol, MCP）TypeScript SDK 中，为远程服务器推荐使用的传输层协议。
*   **核心流式技术**: 该方案利用 Server-Sent Events (SSE) 来实现流式通信，尤其适用于服务器发起的通知。
*   **双向通信**: 协议支持双向通信，允许客户端和服务器互相发送请求。
*   **客户端与服务器实现**:
    *   **客户端**: 客户端通过 `StreamableHTTPClientTransport` 类来连接远程 HTTP 服务器。
    *   **文件结构**: 其实现分布在客户端和服务器的软件包中，具体路径分别为 `packages/client/src/client/streamableHttp.ts` 和 `packages/server/src/server/streamableHttp.ts`。
    *   **服务器**: 服务器可以实现为有状态（stateful）或无状态（stateless）的模式。
*   **安全与认证**: 客户端可以在 Streamable HTTP 请求中附加 OAuth 凭证，以连接到受保护的服务器。
*   **高级应用**: 对于更复杂的场景，Streamable HTTP 可以与发布/订阅（pub/sub）模型结合使用，以便在不同节点之间管理会话状态。
*   **参考示例**: SDK 提供了可运行的客户端和服务器示例代码，如 `simpleStreamableHttp.ts`，用于演示此传输协议的用法。

Search Query: source code function for parsing multipart/mixed stream boundary in file "streamableHttp.ts" from github repository "modelcontextprotocol/typescript-sdk"
Search Answer: 很抱歉，根据提供的资料，无法找到您所查询的关于 `streamableHttp.ts` 文件中解析 `multipart/mixed` 流边界的具体源代码或实现方案。

现有资料显示，搜索结果指向了以下几类信息，但均未包含核心的实现逻辑：
*   一些不相关的 multipart 解析器库。
*   其他库中关于 multipart 解析的相关 GitHub 问题和讨论（例如 [https://github.com/Http-Multipart-Data-Parser/Http-Multipart-Data-Parser/issues/106](https://github.com/Http-Multipart-Data-Parser/Http-Multipart-Data-Parser/issues/106), [https://github.com/mjackson/multipart-parser](https://github.com/mjackson/multipart-parser)）。
*   在 `typescript-sdk` 代码库中的一个示例服务器实现文件（`simpleStatelessStreamableHttp.ts`），该文件展示了如何使用此功能，而非其内部解析逻辑本身（[https://github.com/modelcontextprotocol/typescript-sdk/blob/main/src/examples/server/simpleStatelessStreamableHttp.ts](https://github.com/modelcontextprotocol/typescript-sdk/blob/main/src/examples/server/simpleStatelessStreamableHttp.ts)）。

因此，无法提供工程中关于流式 HTTP 具体解析部分的实现细节。

